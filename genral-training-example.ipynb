{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('gpu2')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n gpu2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__  import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('gpu2')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n gpu2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('gpu2')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n gpu2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "fights_train = np.zeros((700, 40, 160, 160, 3), dtype=np.float64)\n",
    "labels_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndef cut_save(main_dir,mod):\\n    i=0\\n    for x in os.listdir(main_dir):\\n        td = main_dir+x+'/'\\n        for file in os.listdir(td): \\n            fl = os.path.join(td, file)\\n            videos = capture(fl)\\n            if mod == 'train':\\n                fights_train[i][:][:] = videos\\n                i +=1\\n            if x =='fights':\\n                labels_train.append(1)\\n            else:\\n                labels_train.append(0)\\n                \\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def capture(filename):\n",
    "    frames = np.zeros((40, 160, 160, 3), dtype=np.float64)\n",
    "    i=0\n",
    "    vc = cv2.VideoCapture(filename)\n",
    "    if vc.isOpened():\n",
    "        rval , frame = vc.read()\n",
    "    else:\n",
    "        rval = False\n",
    "    #frm = cv2.resize(frame,(200,200))\n",
    "    frm = resize(frame,(160, 160, 3))\n",
    "    frm = np.expand_dims(frm,axis=0)\n",
    "    if(np.max(frm)>1):\n",
    "        frm = frm/255.0\n",
    "    frames[i][:] = frm\n",
    "    i +=1\n",
    "    while i < 40:\n",
    "        rval, frame = vc.read()\n",
    "        #print(i)\n",
    "        #plt.imshow(frame)\n",
    "        #plt.show()\n",
    "        #frm = cv2.resize(frame,(200,200))\n",
    "        frm = resize(frame,(160, 160, 3))\n",
    "        frm = np.expand_dims(frm,axis=0)\n",
    "        if(np.max(frm)>1):\n",
    "            frm = frm/255.0\n",
    "        frames[i][:] = frm\n",
    "        i +=1\n",
    "        #print(frame)\n",
    "    return frames\n",
    "\n",
    "def cut_save(main_dir,mod):\n",
    "    i = 0\n",
    "    #fights = np.zeros((399, 40, 200, 200, 3), dtype=np.float)\n",
    "    #noFights = np.zeros((599, 42, 200, 200, 3), dtype=np.float)\n",
    "    for x in os.listdir(main_dir):\n",
    "        if 1 == 1:\n",
    "            td = main_dir+x+'/'\n",
    "            #for y in os.listdir(main_dir+x+'/'):\n",
    "                #print(y)\n",
    "            for file in os.listdir(td):\n",
    "                fl = os.path.join(td, file)\n",
    "                videos = capture(fl)\n",
    "                if mod == 'train':\n",
    "                    fights_train[i][:][:] = videos\n",
    "                    i +=1\n",
    "                    if x =='fights':\n",
    "                        labels_train.append(1)\n",
    "                    else:\n",
    "                        labels_train.append(0)\n",
    "                elif mod =='test':\n",
    "                    fights_test[i][:][:] = videos\n",
    "                    i +=1\n",
    "                    if x =='fights':\n",
    "                        labels_test.append(1)\n",
    "                    else:\n",
    "                        labels_test.append(0)\n",
    "                elif mod =='val':\n",
    "                    fights_val[i][:][:] = videos\n",
    "                    i +=1\n",
    "                    if x =='fights':\n",
    "                        labels_val.append(1)\n",
    "                    else:\n",
    "                        labels_val.append(0)\n",
    "'''\n",
    "\n",
    "def cut_save(main_dir,mod):\n",
    "    i=0\n",
    "    for x in os.listdir(main_dir):\n",
    "        td = main_dir+x+'/'\n",
    "        for file in os.listdir(td): \n",
    "            fl = os.path.join(td, file)\n",
    "            videos = capture(fl)\n",
    "            if mod == 'train':\n",
    "                fights_train[i][:][:] = videos\n",
    "                i +=1\n",
    "            if x =='fights':\n",
    "                labels_train.append(1)\n",
    "            else:\n",
    "                labels_train.append(0)\n",
    "                \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 700 is out of bounds for axis 0 with size 700",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcut_save\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./trainm/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mcut_save\u001b[1;34m(main_dir, mod)\u001b[0m\n\u001b[0;32m     42\u001b[0m videos \u001b[38;5;241m=\u001b[39m capture(fl)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 44\u001b[0m     \u001b[43mfights_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[:][:] \u001b[38;5;241m=\u001b[39m videos\n\u001b[0;32m     45\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfights\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 700 is out of bounds for axis 0 with size 700"
     ]
    }
   ],
   "source": [
    "cut_save('./trainm/',\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fights_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, fights_test, y_train, labels_test = train_test_split(fights_train,labels_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fights_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fights_test= np.zeros((300, 40, 160, 160, 3), dtype=np.float)\n",
    "labels_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_save('./testm/',\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fights_test[19][5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers\n",
    "models = tf.keras.models\n",
    "losses = tf.keras.losses\n",
    "optimizers = tf.keras.optimizers \n",
    "metrics = tf.keras.metrics\n",
    "utils = tf.keras.utils\n",
    "callbacks = tf.keras.callbacks\n",
    "layers = tf.keras.layers\n",
    "models = tf.keras.models\n",
    "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "losses = tf.keras.losses\n",
    "optimizers = tf.keras.optimizers \n",
    "metrics = tf.keras.metrics\n",
    "utils = tf.keras.utils\n",
    "callbacks = tf.keras.callbacks\n",
    "\n",
    "plot_model = tf.keras.utils.plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "num_classes = 2\n",
    "vg19 = tf.keras.applications.vgg19.VGG19\n",
    "base_model = vg19(include_top=False,weights='imagenet',input_shape=(160, 160,3))\n",
    "# Freeze the layers except the last 4 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# Check the trainable status of the individual layers\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "cnn = models.Sequential()\n",
    "cnn.add(base_model)\n",
    "cnn.add(layers.Flatten())\n",
    "#cnn.add(layers.Dense(1024, activation='relu'))\n",
    "#cnn.add(layers.Dropout(0.3))\n",
    "#cnn.add(layers.Dense(512, activation='relu'))\n",
    "#cnn.add(layers.Dropout(0.3))\n",
    "#cnn.add(layers.LSTM(40))\n",
    "\n",
    "# define LSTM model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.TimeDistributed(cnn,  input_shape=(40, 160, 160, 3)))\n",
    "model.add(layers.LSTM(40 , return_sequences=True))\n",
    "\n",
    "#model.add(layers.Dense(num_classes, activation=\"sigmoid\"))\n",
    "#model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.TimeDistributed(layers.Dense(160, activation='relu')))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling1D(name=\"globale\"))\n",
    "\n",
    "'''\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "'''\n",
    "model.add(layers.Dense(num_classes, activation=\"sigmoid\" , name=\"last\"))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.load_weights('mamon98777.hdf5')\n",
    "rms = optimizers.RMSprop()\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AccuracyHistory(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "\n",
    "history = AccuracyHistory()\n",
    "earlyStopping = callbacks.EarlyStopping(monitor='val_loss', patience=8,min_delta=1e-5, verbose=0, mode='min')\n",
    "mcp_save = callbacks.ModelCheckpoint('mamon98777.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = callbacks.ReduceLROnPlateau(monitor='val_loss',patience=1, verbose=2,factor=0.5,min_lr=0.0000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =3\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = utils.to_categorical(labels_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = utils.to_categorical(labels_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "millis = int(round(time.time() * 1000))\n",
    "print(\"started at \" , millis)\n",
    "\n",
    "model.fit(fights_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(fights_test, y_test),callbacks=[earlyStopping, mcp_save, reduce_lr_loss,history])\n",
    "\n",
    "#0.8995 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fights_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.acc\n",
    "val_acc = history.val_acc\n",
    "loss = history.loss\n",
    "val_loss = history.val_loss\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fights_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(fights_test, y_test, batch_size=3)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(fights_test , batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprd = Y_pred > 0.5\n",
    "yprd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredicted = []\n",
    "for zero,one in yprd:\n",
    "    if zero == True:\n",
    "        ypredicted.append(0)\n",
    "    else:\n",
    "        ypredicted.append(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "for zero,one in y_test:\n",
    "    if zero == True:\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y,ypredicted)\n",
    "confusion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(confusion, [0,1], figsize = (30,15), fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(y, ypredicted, target_names=['no-violance','violance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"mamonbest980hocky.hdfs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('gpu2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef829ca81cbbb7605d13da85eb846bc5c12e97516840a6ec927f917a0b474f6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
